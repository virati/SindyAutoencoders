{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from example_lorenz import get_lorenz_data\n",
    "from sindy_utils import library_size\n",
    "from training import train_network\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training, validation, testing data\n",
    "noise_strength = 1e-6\n",
    "training_data = get_lorenz_data(1024, noise_strength=noise_strength)\n",
    "validation_data = get_lorenz_data(20, noise_strength=noise_strength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method keys of dict object at 0x7f9df3b2ad20>\n"
     ]
    }
   ],
   "source": [
    "print(training_data.keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "params['input_dim'] = 128\n",
    "params['latent_dim'] = 3\n",
    "params['model_order'] = 1\n",
    "params['poly_order'] = 3\n",
    "params['include_sine'] = False\n",
    "params['library_dim'] = library_size(params['latent_dim'], params['poly_order'], params['include_sine'], True)\n",
    "\n",
    "# sequential thresholding parameters\n",
    "params['sequential_thresholding'] = True\n",
    "params['coefficient_threshold'] = 0.1\n",
    "params['threshold_frequency'] = 500\n",
    "params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "params['coefficient_initialization'] = 'constant'\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_z'] = 0.0\n",
    "params['loss_weight_sindy_x'] = 1e-4\n",
    "params['loss_weight_sindy_regularization'] = 1e-5\n",
    "\n",
    "params['activation'] = 'sigmoid'\n",
    "params['widths'] = [64,32]\n",
    "\n",
    "# training parameters\n",
    "params['epoch_size'] = training_data['x'].shape[0]\n",
    "params['batch_size'] = 1024\n",
    "params['learning_rate'] = 1e-3\n",
    "\n",
    "params['data_path'] = os.getcwd() + '/'\n",
    "params['print_progress'] = True\n",
    "params['print_frequency'] = 100\n",
    "\n",
    "# training time cutoffs\n",
    "params['max_epochs'] = 5001\n",
    "params['refinement_epochs'] = 1001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 0\n",
      "WARNING:tensorflow:From ../../src/autoencoder.py:27: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../src/autoencoder.py:193: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From ../../src/training.py:12: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/virati/py_37_env/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From ../../src/training.py:14: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../src/training.py:14: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../src/training.py:14: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "TRAINING\n",
      "WARNING:tensorflow:From ../../src/training.py:28: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From ../../src/training.py:29: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "Epoch 0\n",
      "   training loss 0.052101969718933105, (0.049204864, 719.3249, 28.887875, 0.83171767)\n",
      "   validation loss 0.04142506793141365, (0.03991425, 705.9839, 15.024999, 0.83171767)\n",
      "decoder loss ratio: 0.207344, decoder SINDy loss  ratio: 1.071556\n",
      "Epoch 100\n",
      "   training loss 7.01112367096357e-05, (2.6617083e-05, 1.1087452, 0.24516542, 1.8977612)\n",
      "   validation loss 5.688281817128882e-05, (2.1907117e-05, 1.065106, 0.15998088, 1.8977612)\n",
      "decoder loss ratio: 0.000114, decoder SINDy loss  ratio: 0.011410\n",
      "Epoch 200\n",
      "   training loss 2.9917171559645794e-05, (7.4781365e-06, 0.28318334, 0.059636153, 1.6475421)\n",
      "   validation loss 2.556778235884849e-05, (6.307181e-06, 0.109168135, 0.027851816, 1.6475421)\n",
      "decoder loss ratio: 0.000033, decoder SINDy loss  ratio: 0.001986\n",
      "Epoch 300\n",
      "   training loss 2.5218296286766417e-05, (7.821276e-06, 0.18449245, 0.04038777, 1.3358244)\n",
      "   validation loss 2.1532992832362652e-05, (6.417857e-06, 0.0808869, 0.017568922, 1.3358244)\n",
      "decoder loss ratio: 0.000033, decoder SINDy loss  ratio: 0.001253\n",
      "Epoch 400\n",
      "   training loss 2.125119135598652e-05, (7.374383e-06, 0.21634726, 0.032682113, 1.0608597)\n",
      "   validation loss 1.8680580978980288e-05, (6.3170514e-06, 0.08842209, 0.017549338, 1.0608597)\n",
      "decoder loss ratio: 0.000033, decoder SINDy loss  ratio: 0.001252\n",
      "Epoch 500\n",
      "   training loss 1.4714039025420789e-05, (3.1907607e-06, 0.19180374, 0.02380582, 0.9142697)\n",
      "   validation loss 1.3015494914725423e-05, (2.8850397e-06, 0.07015556, 0.009877587, 0.9142697)\n",
      "decoder loss ratio: 0.000015, decoder SINDy loss  ratio: 0.000704\n",
      "THRESHOLDING: 17 active coefficients\n",
      "Epoch 600\n",
      "   training loss 1.6630121535854414e-05, (5.6714534e-06, 0.19428934, 0.022516198, 0.8707048)\n",
      "   validation loss 1.4964867659728043e-05, (5.1387215e-06, 0.06876945, 0.011190974, 0.8707048)\n",
      "decoder loss ratio: 0.000027, decoder SINDy loss  ratio: 0.000798\n",
      "Epoch 700\n",
      "   training loss 1.5736512068542652e-05, (5.141548e-06, 0.24883275, 0.021419633, 0.8453)\n",
      "   validation loss 1.3845443390891887e-05, (4.3928326e-06, 0.08902845, 0.009996111, 0.8453)\n",
      "decoder loss ratio: 0.000023, decoder SINDy loss  ratio: 0.000713\n",
      "Epoch 800\n",
      "   training loss 1.5877794794505462e-05, (5.6610015e-06, 0.29282638, 0.019502593, 0.8266535)\n",
      "   validation loss 1.4478888260782696e-05, (5.1837433e-06, 0.10607938, 0.010286106, 0.8266535)\n",
      "decoder loss ratio: 0.000027, decoder SINDy loss  ratio: 0.000734\n",
      "Epoch 900\n",
      "   training loss 1.4337686479848344e-05, (4.3551404e-06, 0.3247728, 0.018666048, 0.8115941)\n",
      "   validation loss 1.3285693967191037e-05, (4.2007737e-06, 0.12330625, 0.009689787, 0.8115941)\n",
      "decoder loss ratio: 0.000022, decoder SINDy loss  ratio: 0.000691\n",
      "Epoch 1000\n",
      "   training loss 1.515775056759594e-05, (5.2507276e-06, 0.2990972, 0.019134333, 0.799359)\n",
      "   validation loss 1.3668956853507552e-05, (4.6728214e-06, 0.14079995, 0.010025457, 0.799359)\n",
      "decoder loss ratio: 0.000024, decoder SINDy loss  ratio: 0.000715\n",
      "THRESHOLDING: 10 active coefficients\n",
      "Epoch 1100\n",
      "   training loss 1.5826430171728134e-05, (5.7910797e-06, 0.34020996, 0.020982355, 0.7937116)\n",
      "   validation loss 1.446340775146382e-05, (5.4419847e-06, 0.14900555, 0.010843072, 0.7937116)\n",
      "decoder loss ratio: 0.000028, decoder SINDy loss  ratio: 0.000773\n",
      "Epoch 1200\n",
      "   training loss 1.2376423001114745e-05, (3.1410002e-06, 0.30458868, 0.014002761, 0.78351474)\n",
      "   validation loss 1.1600762263697106e-05, (2.9908963e-06, 0.18492559, 0.0077471947, 0.78351474)\n",
      "decoder loss ratio: 0.000016, decoder SINDy loss  ratio: 0.000553\n",
      "Epoch 1300\n",
      "   training loss 1.560507735121064e-05, (6.083229e-06, 0.3984127, 0.017708847, 0.77509636)\n",
      "   validation loss 1.4705610738019459e-05, (5.9836293e-06, 0.1846207, 0.009710183, 0.77509636)\n",
      "decoder loss ratio: 0.000031, decoder SINDy loss  ratio: 0.000693\n",
      "Epoch 1400\n",
      "   training loss 1.5175644875853322e-05, (5.673516e-06, 0.36501503, 0.018253747, 0.7676754)\n",
      "   validation loss 1.402257021254627e-05, (5.384448e-06, 0.19959517, 0.009613689, 0.7676754)\n",
      "decoder loss ratio: 0.000028, decoder SINDy loss  ratio: 0.000686\n",
      "Epoch 1500\n",
      "   training loss 1.4969058611313812e-05, (5.718905e-06, 0.38274875, 0.016345873, 0.7615567)\n",
      "   validation loss 1.385973700962495e-05, (5.4162456e-06, 0.20138688, 0.008279247, 0.7615567)\n",
      "decoder loss ratio: 0.000028, decoder SINDy loss  ratio: 0.000590\n",
      "THRESHOLDING: 7 active coefficients\n",
      "Epoch 1600\n",
      "   training loss 1.1216874554520473e-05, (2.3987566e-06, 0.33927444, 0.012142168, 0.76039016)\n",
      "   validation loss 1.0816856047313195e-05, (2.560264e-06, 0.2256705, 0.006526909, 0.76039016)\n",
      "decoder loss ratio: 0.000013, decoder SINDy loss  ratio: 0.000465\n",
      "Epoch 1700\n",
      "   training loss 1.2793892892659642e-05, (3.9964207e-06, 0.35878453, 0.012538653, 0.75436074)\n",
      "   validation loss 1.2115069694118574e-05, (3.9113156e-06, 0.2255471, 0.0066014663, 0.75436074)\n",
      "decoder loss ratio: 0.000020, decoder SINDy loss  ratio: 0.000471\n",
      "Epoch 1800\n",
      "   training loss 1.0434658179292455e-05, (1.9168751e-06, 0.3141532, 0.010243694, 0.74934137)\n",
      "   validation loss 9.992584637075197e-06, (2.0142018e-06, 0.23187698, 0.0048496895, 0.74934137)\n",
      "decoder loss ratio: 0.000010, decoder SINDy loss  ratio: 0.000346\n",
      "Epoch 1900\n",
      "   training loss 1.4491623915091623e-05, (5.8154715e-06, 0.36907092, 0.012328807, 0.7443272)\n",
      "   validation loss 1.4277728041633964e-05, (6.0959596e-06, 0.22282915, 0.007384967, 0.7443272)\n",
      "decoder loss ratio: 0.000032, decoder SINDy loss  ratio: 0.000527\n",
      "Epoch 2000\n",
      "   training loss 1.6345118638128042e-05, (7.5140756e-06, 0.41993153, 0.014278893, 0.74031544)\n",
      "   validation loss 1.578293631609995e-05, (7.6400365e-06, 0.24883439, 0.007397457, 0.74031544)\n",
      "decoder loss ratio: 0.000040, decoder SINDy loss  ratio: 0.000528\n",
      "THRESHOLDING: 7 active coefficients\n",
      "Epoch 2100\n",
      "   training loss 1.8848440959118307e-05, (1.0109341e-05, 0.41811064, 0.013754405, 0.736366)\n",
      "   validation loss 1.7656824638834223e-05, (9.747106e-06, 0.27675653, 0.005460587, 0.736366)\n",
      "decoder loss ratio: 0.000051, decoder SINDy loss  ratio: 0.000389\n",
      "Epoch 2200\n",
      "   training loss 1.7199245121446438e-05, (8.812189e-06, 0.4257973, 0.010572616, 0.7329795)\n",
      "   validation loss 1.5791363694006577e-05, (7.846582e-06, 0.3474273, 0.0061498713, 0.7329795)\n",
      "decoder loss ratio: 0.000041, decoder SINDy loss  ratio: 0.000439\n",
      "Epoch 2300\n",
      "   training loss 9.827506801229902e-06, (1.7255986e-06, 0.40627465, 0.0079937335, 0.73025346)\n",
      "   validation loss 9.476812920183875e-06, (1.7324353e-06, 0.28291067, 0.0044184276, 0.73025346)\n",
      "decoder loss ratio: 0.000009, decoder SINDy loss  ratio: 0.000315\n",
      "Epoch 2400\n",
      "   training loss 1.2151482223998755e-05, (3.7213024e-06, 0.46704635, 0.011494683, 0.72807115)\n",
      "   validation loss 1.1496947990963235e-05, (3.572935e-06, 0.36496785, 0.0064330194, 0.72807115)\n",
      "decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.000459\n",
      "Epoch 2500\n",
      "   training loss 1.259861710423138e-05, (4.5006086e-06, 0.5004179, 0.008384368, 0.72595716)\n",
      "   validation loss 1.278065701626474e-05, (4.7348635e-06, 0.38781735, 0.007862224, 0.72595716)\n",
      "decoder loss ratio: 0.000025, decoder SINDy loss  ratio: 0.000561\n",
      "THRESHOLDING: 7 active coefficients\n",
      "Epoch 2600\n",
      "   training loss 1.3243590728961863e-05, (4.785975e-06, 0.6776667, 0.012212735, 0.7236342)\n",
      "   validation loss 1.2544449418783188e-05, (4.7148615e-06, 0.36587694, 0.005932466, 0.7236342)\n",
      "decoder loss ratio: 0.000024, decoder SINDy loss  ratio: 0.000423\n",
      "Epoch 2700\n",
      "   training loss 1.103208342101425e-05, (2.8348186e-06, 0.57512015, 0.0097885, 0.72184145)\n",
      "   validation loss 1.0475948329258244e-05, (2.577766e-06, 0.36720124, 0.006797682, 0.72184145)\n",
      "decoder loss ratio: 0.000013, decoder SINDy loss  ratio: 0.000485\n",
      "Epoch 2800\n",
      "   training loss 1.282437369809486e-05, (4.5021598e-06, 0.7012599, 0.011182049, 0.7204009)\n",
      "   validation loss 1.1589685527724214e-05, (3.8568924e-06, 0.4127263, 0.0052878424, 0.7204009)\n",
      "decoder loss ratio: 0.000020, decoder SINDy loss  ratio: 0.000377\n",
      "Epoch 2900\n",
      "   training loss 1.1198741958651226e-05, (3.1850677e-06, 0.72002745, 0.008311334, 0.7182541)\n",
      "   validation loss 1.0872671737161e-05, (3.1524523e-06, 0.38946277, 0.0053767893, 0.7182541)\n",
      "decoder loss ratio: 0.000016, decoder SINDy loss  ratio: 0.000383\n",
      "Epoch 3000\n",
      "   training loss 1.0965973160637077e-05, (2.8506784e-06, 0.7822948, 0.009489117, 0.7166383)\n",
      "   validation loss 1.0155154086533003e-05, (2.4926253e-06, 0.4787942, 0.00496146, 0.7166383)\n",
      "decoder loss ratio: 0.000013, decoder SINDy loss  ratio: 0.000354\n",
      "THRESHOLDING: 7 active coefficients\n",
      "Epoch 3100\n",
      "   training loss 1.1432871360739227e-05, (3.4133964e-06, 0.8180353, 0.008688349, 0.71506405)\n",
      "   validation loss 1.1080519470851868e-05, (3.4062073e-06, 0.4578617, 0.0052367263, 0.71506405)\n",
      "decoder loss ratio: 0.000018, decoder SINDy loss  ratio: 0.000373\n",
      "Epoch 3200\n",
      "   training loss 1.1135284694319125e-05, (3.1362897e-06, 0.91359395, 0.008652706, 0.71337247)\n",
      "   validation loss 1.1172805898240767e-05, (3.4855138e-06, 0.51574963, 0.0055356724, 0.71337247)\n",
      "decoder loss ratio: 0.000018, decoder SINDy loss  ratio: 0.000395\n",
      "Epoch 3300\n",
      "   training loss 1.5104738849913701e-05, (6.610945e-06, 1.1603826, 0.013696318, 0.71241623)\n",
      "   validation loss 1.579986019351054e-05, (7.4226e-06, 0.44873217, 0.012530983, 0.71241623)\n",
      "decoder loss ratio: 0.000039, decoder SINDy loss  ratio: 0.000894\n",
      "Epoch 3400\n",
      "   training loss 1.0012845450546592e-05, (2.0826456e-06, 0.83444816, 0.0081545655, 0.71147436)\n",
      "   validation loss 9.793620847631246e-06, (2.1253659e-06, 0.472888, 0.0055351183, 0.71147436)\n",
      "decoder loss ratio: 0.000011, decoder SINDy loss  ratio: 0.000395\n",
      "Epoch 3500\n",
      "   training loss 1.0282177754561417e-05, (2.3785258e-06, 0.9055167, 0.007983472, 0.71053046)\n",
      "   validation loss 1.0484749509487301e-05, (2.51414e-06, 0.43764782, 0.0086530475, 0.71053046)\n",
      "decoder loss ratio: 0.000013, decoder SINDy loss  ratio: 0.000617\n",
      "THRESHOLDING: 7 active coefficients\n",
      "Epoch 3600\n",
      "   training loss 1.1679168892442249e-05, (3.6736392e-06, 1.1526247, 0.009113813, 0.70941484)\n",
      "   validation loss 1.260409590031486e-05, (4.4633593e-06, 0.3936376, 0.010465886, 0.70941484)\n",
      "decoder loss ratio: 0.000023, decoder SINDy loss  ratio: 0.000746\n",
      "Epoch 3700\n",
      "   training loss 9.794852303457446e-06, (1.8012302e-06, 1.1782024, 0.009056266, 0.70879954)\n",
      "   validation loss 1.0489230589882936e-05, (2.4590722e-06, 0.40798908, 0.009421634, 0.70879954)\n",
      "decoder loss ratio: 0.000013, decoder SINDy loss  ratio: 0.000672\n",
      "Epoch 3800\n",
      "   training loss 9.464439244766254e-06, (1.5846092e-06, 1.2492138, 0.008032267, 0.7076604)\n",
      "   validation loss 1.0262276191497222e-05, (2.2949978e-06, 0.40060118, 0.0089067435, 0.7076604)\n",
      "decoder loss ratio: 0.000012, decoder SINDy loss  ratio: 0.000635\n",
      "Epoch 3900\n",
      "   training loss 1.0512138032936491e-05, (2.750987e-06, 1.3093115, 0.006917925, 0.7069358)\n",
      "   validation loss 1.1861227903864346e-05, (3.5329015e-06, 0.3873311, 0.012589684, 0.7069358)\n",
      "decoder loss ratio: 0.000018, decoder SINDy loss  ratio: 0.000898\n",
      "Epoch 4000\n",
      "   training loss 1.0055306120193563e-05, (2.3597502e-06, 1.4081589, 0.0063382704, 0.70617294)\n",
      "   validation loss 1.118261025112588e-05, (3.2849248e-06, 0.39001536, 0.008359567, 0.70617294)\n",
      "decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.000596\n",
      "THRESHOLDING: 7 active coefficients\n",
      "Epoch 4100\n",
      "   training loss 1.2708840586128645e-05, (4.2386973e-06, 1.6548, 0.0141994, 0.70502037)\n",
      "   validation loss 1.2235433132445905e-05, (4.1368903e-06, 0.41159695, 0.010483396, 0.70502037)\n",
      "decoder loss ratio: 0.000021, decoder SINDy loss  ratio: 0.000748\n",
      "Epoch 4200\n",
      "   training loss 1.6528745618415996e-05, (8.46927e-06, 1.7741632, 0.010117371, 0.7047737)\n",
      "   validation loss 1.714625977911055e-05, (9.35953e-06, 0.537795, 0.0073899324, 0.7047737)\n",
      "decoder loss ratio: 0.000049, decoder SINDy loss  ratio: 0.000527\n",
      "Epoch 4300\n",
      "   training loss 1.0620990906318184e-05, (2.9747296e-06, 1.2682662, 0.0060535483, 0.70409065)\n",
      "   validation loss 1.1426508535805624e-05, (3.6361394e-06, 0.45703757, 0.0074946275, 0.70409065)\n",
      "decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.000535\n",
      "Epoch 4400\n",
      "   training loss 1.3926899555372074e-05, (5.899178e-06, 1.499074, 0.009935423, 0.7034179)\n",
      "   validation loss 1.4496823496301658e-05, (6.6596417e-06, 0.47811902, 0.008030024, 0.7034179)\n",
      "decoder loss ratio: 0.000035, decoder SINDy loss  ratio: 0.000573\n",
      "Epoch 4500\n",
      "   training loss 1.65924102475401e-05, (8.5130705e-06, 1.4289827, 0.010531534, 0.7026187)\n",
      "   validation loss 1.9389772205613554e-05, (1.152249e-05, 0.42545477, 0.008410941, 0.7026187)\n",
      "decoder loss ratio: 0.000060, decoder SINDy loss  ratio: 0.000600\n",
      "THRESHOLDING: 7 active coefficients\n",
      "Epoch 4600\n",
      "   training loss 1.6637401131447405e-05, (8.739907e-06, 1.4498879, 0.008774571, 0.70200384)\n",
      "   validation loss 1.889005216071382e-05, (1.0778811e-05, 0.3656044, 0.010912032, 0.70200384)\n",
      "decoder loss ratio: 0.000056, decoder SINDy loss  ratio: 0.000778\n",
      "Epoch 4700\n",
      "   training loss 1.1589890164032113e-05, (3.6223114e-06, 1.4674559, 0.009529528, 0.7014626)\n",
      "   validation loss 1.1141024515382014e-05, (3.5956175e-06, 0.4994881, 0.005307805, 0.7014626)\n",
      "decoder loss ratio: 0.000019, decoder SINDy loss  ratio: 0.000379\n",
      "Epoch 4800\n",
      "   training loss 1.0093326636706479e-05, (2.4953783e-06, 1.5220982, 0.0058846585, 0.7009483)\n",
      "   validation loss 1.0988203939632513e-05, (3.5112687e-06, 0.43906093, 0.004674527, 0.7009483)\n",
      "decoder loss ratio: 0.000018, decoder SINDy loss  ratio: 0.000333\n",
      "Epoch 4900\n",
      "   training loss 1.2361348126432858e-05, (4.518078e-06, 1.6700503, 0.008364236, 0.7006846)\n",
      "   validation loss 1.1537686077645048e-05, (4.0903215e-06, 0.665521, 0.0044051916, 0.7006846)\n",
      "decoder loss ratio: 0.000021, decoder SINDy loss  ratio: 0.000314\n",
      "Epoch 5000\n",
      "   training loss 9.990168109652586e-06, (2.273241e-06, 1.0772632, 0.007138921, 0.7003035)\n",
      "   validation loss 9.716493877931498e-06, (2.333867e-06, 0.6113123, 0.0037959171, 0.7003035)\n",
      "decoder loss ratio: 0.000012, decoder SINDy loss  ratio: 0.000271\n",
      "THRESHOLDING: 7 active coefficients\n",
      "REFINEMENT\n",
      "Epoch 0\n",
      "   training loss 4.445645572559442e-06, (3.5813812e-06, 1.1769621, 0.008642645, 0.7035824)\n",
      "   validation loss 3.0331186735566007e-06, (2.6299606e-06, 0.546616, 0.0040315813, 0.7035824)\n",
      "decoder loss ratio: 0.000014, decoder SINDy loss  ratio: 0.000288\n",
      "Epoch 100\n",
      "   training loss 2.267113131892984e-06, (1.8549814e-06, 1.3328032, 0.0041213166, 0.7185527)\n",
      "   validation loss 2.418133362880326e-06, (2.1260767e-06, 0.5172709, 0.0029205673, 0.7185527)\n",
      "decoder loss ratio: 0.000011, decoder SINDy loss  ratio: 0.000208\n",
      "Epoch 200\n",
      "   training loss 2.594465058791684e-06, (2.1239343e-06, 1.6719683, 0.004705307, 0.7210808)\n",
      "   validation loss 2.1656223907484673e-06, (1.9468616e-06, 0.5268992, 0.0021876073, 0.7210808)\n",
      "decoder loss ratio: 0.000010, decoder SINDy loss  ratio: 0.000156\n",
      "Epoch 300\n",
      "   training loss 3.788811227423139e-06, (3.1816896e-06, 2.4413252, 0.0060712174, 0.7229099)\n",
      "   validation loss 3.61615207111754e-06, (3.3045308e-06, 0.6269729, 0.0031162137, 0.7229099)\n",
      "decoder loss ratio: 0.000017, decoder SINDy loss  ratio: 0.000222\n",
      "Epoch 400\n",
      "   training loss 2.3638731363462284e-06, (2.0946968e-06, 1.7038679, 0.002691764, 0.7246142)\n",
      "   validation loss 3.151039891235996e-06, (2.755646e-06, 0.3609181, 0.003953939, 0.7246142)\n",
      "decoder loss ratio: 0.000014, decoder SINDy loss  ratio: 0.000282\n",
      "Epoch 500\n",
      "   training loss 3.2321659091394395e-06, (2.71421e-06, 1.9430714, 0.00517956, 0.7258554)\n",
      "   validation loss 3.0259070626925677e-06, (2.7425353e-06, 0.4485168, 0.002833717, 0.7258554)\n",
      "decoder loss ratio: 0.000014, decoder SINDy loss  ratio: 0.000202\n",
      "Epoch 600\n",
      "   training loss 1.0892154932662379e-05, (9.7615675e-06, 1.7315589, 0.011305877, 0.72701937)\n",
      "   validation loss 8.967847861640621e-06, (8.500513e-06, 0.49591708, 0.004673349, 0.72701937)\n",
      "decoder loss ratio: 0.000044, decoder SINDy loss  ratio: 0.000333\n",
      "Epoch 700\n",
      "   training loss 3.8016733014956117e-06, (3.2948126e-06, 1.6463438, 0.0050686086, 0.7281198)\n",
      "   validation loss 2.94963183478103e-06, (2.6906323e-06, 0.42534602, 0.0025899957, 0.7281198)\n",
      "decoder loss ratio: 0.000014, decoder SINDy loss  ratio: 0.000185\n",
      "Epoch 800\n",
      "   training loss 1.0351286618970335e-05, (9.430597e-06, 2.0157027, 0.009206899, 0.72925323)\n",
      "   validation loss 1.04256014310522e-05, (9.910504e-06, 0.66606915, 0.0051509757, 0.72925323)\n",
      "decoder loss ratio: 0.000051, decoder SINDy loss  ratio: 0.000367\n",
      "Epoch 900\n",
      "   training loss 7.099445610947441e-06, (6.575404e-06, 1.79322, 0.0052404194, 0.7303117)\n",
      "   validation loss 6.840783044026466e-06, (6.4292326e-06, 0.5032743, 0.0041155056, 0.7303117)\n",
      "decoder loss ratio: 0.000033, decoder SINDy loss  ratio: 0.000294\n",
      "Epoch 1000\n",
      "   training loss 2.676611302376841e-06, (2.342444e-06, 1.3089088, 0.003341673, 0.7311366)\n",
      "   validation loss 2.2485482986667193e-06, (2.0570378e-06, 0.47131866, 0.0019151049, 0.7311366)\n",
      "decoder loss ratio: 0.000011, decoder SINDy loss  ratio: 0.000137\n"
     ]
    }
   ],
   "source": [
    "num_experiments = 1\n",
    "df = pd.DataFrame()\n",
    "for i in range(num_experiments):\n",
    "    print('EXPERIMENT %d' % i)\n",
    "\n",
    "    params['coefficient_mask'] = np.ones((params['library_dim'], params['latent_dim']))\n",
    "\n",
    "    params['save_name'] = 'lorenz_' + datetime.datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S_%f\")\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    results_dict = train_network(training_data, validation_data, params)\n",
    "    df = df.append({**results_dict, **params}, ignore_index=True)\n",
    "\n",
    "df.to_pickle('experiment_results_' + datetime.datetime.now().strftime(\"%Y%m%d%H%M\") + '.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_37_env",
   "language": "python",
   "name": "py_37_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
